# Agentic Layer - Complete Architecture

## Overview

The agentic layer is a conversational AI system that allows users to create visualizations and analyze data through natural language. It intelligently interprets user queries, generates structured actions, and executes them on the canvas.

## System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         User Query                          â”‚
â”‚              "Show revenue by state and explain"            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AgentChatPanel.jsx                       â”‚
â”‚  â€¢ Captures user input                                      â”‚
â”‚  â€¢ Displays conversation history                            â”‚
â”‚  â€¢ Shows loading states and errors                          â”‚
â”‚  â€¢ Tracks token usage                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   canvasSnapshot.js                         â”‚
â”‚  â€¢ Extracts current canvas state                            â”‚
â”‚  â€¢ Captures: charts, tables, textboxes                      â”‚
â”‚  â€¢ Provides "eyes" to the agent                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Backend: /agent-query                       â”‚
â”‚  â€¢ Receives: user_query + canvas_state + dataset_id         â”‚
â”‚  â€¢ Retrieves dataset metadata                               â”‚
â”‚  â€¢ Constructs enhanced prompt                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Gemini LLM (gemini_llm.py)                     â”‚
â”‚  â€¢ Analyzes query + context + metadata                      â”‚
â”‚  â€¢ Generates structured JSON actions                        â”‚
â”‚  â€¢ Returns reasoning + token usage                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    validation.js                            â”‚
â”‚  â€¢ Validates actions using Zod schemas                      â”‚
â”‚  â€¢ Ensures type safety and correctness                      â”‚
â”‚  â€¢ Returns success or detailed error                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   actionExecutor.js                         â”‚
â”‚  â€¢ Executes validated actions sequentially                  â”‚
â”‚  â€¢ Calls backend endpoints as needed                        â”‚
â”‚  â€¢ Creates shapes on TLDraw canvas                          â”‚
â”‚  â€¢ Returns execution results                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Canvas Updated                           â”‚
â”‚  â€¢ New charts, insights, tables appear                      â”‚
â”‚  â€¢ User sees results immediately                            â”‚
â”‚  â€¢ Can continue conversation                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Component Details

### 1. Frontend Components

#### `AgentChatPanel.jsx`
**Location**: `/frontend/src/agentic_layer/AgentChatPanel.jsx`

**Purpose**: Main UI component for user interaction

**Features**:
- Text input for queries
- Message history display
- Loading indicators
- Error handling
- Token usage tracking
- Requires dataset and API key

**Key Functions**:
```javascript
handleSubmit(e)
  â”œâ”€> getCanvasSnapshot()
  â”œâ”€> fetch('/agent-query')
  â”œâ”€> validateActionsSafe()
  â”œâ”€> executeActions()
  â””â”€> updateMessages()
```

#### `canvasSnapshot.js`
**Location**: `/frontend/src/agentic_layer/canvasSnapshot.js`

**Purpose**: Extract current canvas state for agent context

**Exported Function**:
```javascript
getCanvasSnapshot(editor, nodes)
  â””â”€> Returns: {
        charts: [...],
        tables: [...],
        textBoxes: [...],
        metadata: { nodeCount, chartCount, ... }
      }
```

**What It Captures**:
- **Charts**: dimensions, measures, chartType, position, title
- **Tables**: title, position
- **TextBoxes**: text content, position
- **Metadata**: counts and status

#### `validation.js`
**Location**: `/frontend/src/agentic_layer/validation.js`

**Purpose**: Type-safe validation using Zod schemas

**Schemas Defined**:
- `CreateChartActionSchema`
- `CreateInsightActionSchema`
- `GenerateChartInsightsSchema`
- `AIQuerySchema`
- `ShowTableSchema`
- `AgentActionSchema` (union of all)
- `AgentResponseSchema` (complete response)

**Main Function**:
```javascript
validateActionsSafe(response)
  â””â”€> Returns: { 
        success: true/false, 
        data: validated_data,
        error: error_details 
      }
```

#### `actionExecutor.js`
**Location**: `/frontend/src/agentic_layer/actionExecutor.js`

**Purpose**: Execute validated actions on canvas

**Main Flow**:
```javascript
executeActions(actions, context)
  â””â”€> For each action:
        â”œâ”€> executeAction(action)
        â”‚     â”œâ”€> createChartAction()
        â”‚     â”œâ”€> createInsightAction()
        â”‚     â”œâ”€> generateChartInsightsAction()
        â”‚     â”œâ”€> aiQueryAction()
        â”‚     â””â”€> showTableAction()
        â””â”€> Collect results
```

**Action Handlers**:

1. **`createChartAction`**
   - Calls `/charts` endpoint
   - Uses `figureFromPayload` to format data
   - Creates chart node on canvas
   - Returns chart info

2. **`createInsightAction`**
   - Creates textbox node with provided text
   - Positions relative to reference or center
   - Returns insight info

3. **`generateChartInsightsAction`**
   - Calls `/chart-insights` endpoint
   - Creates textbox with AI-generated insights
   - Positions next to source chart
   - Returns insight info

4. **`aiQueryAction`** â­ (Smart Context Detection)
   - Checks for chartId (3-tier detection):
     1. Explicit chartId from LLM
     2. Selected chart in editor
     3. Falls back to dataset-level
   - Calls `/ai-explore` with chart_id OR dataset_id
   - Creates textbox with Q&A
   - Returns query result

5. **`showTableAction`**
   - Extracts table data from chart node (client-side)
   - Creates table shape next to chart
   - Returns table info

#### `types.js`
**Location**: `/frontend/src/agentic_layer/types.js`

**Purpose**: Central configuration and constants

**Exports**:
```javascript
ACTION_TYPES = {
  CREATE_CHART,
  CREATE_INSIGHT,
  GENERATE_CHART_INSIGHTS,
  AI_QUERY,
  SHOW_TABLE
}

POSITION_TYPES = {
  CENTER,
  RIGHT_OF_CHART,
  BELOW_CHART,
  AUTO
}

AGENT_CONFIG = {
  MAX_ACTIONS_PER_QUERY: 5,
  API_ENDPOINT: '/agent-query',
  DEFAULT_CHART_WIDTH: 800,
  DEFAULT_CHART_HEIGHT: 400,
  ...
}
```

#### `index.js`
**Location**: `/frontend/src/agentic_layer/index.js`

**Purpose**: Public API for the agentic layer module

**Exports**:
```javascript
export { AgentChatPanel } from './AgentChatPanel';
export { getCanvasSnapshot } from './canvasSnapshot';
export { executeActions } from './actionExecutor';
export { validateActionsSafe } from './validation';
export { ACTION_TYPES, POSITION_TYPES, AGENT_CONFIG } from './types';
```

### 2. Backend Components

#### `/agent-query` Endpoint
**Location**: `/backend/app.py`

**Request Model**:
```python
class AgentQueryRequest(BaseModel):
    user_query: str
    canvas_state: Dict[str, Any]
    dataset_id: str
    api_key: Optional[str] = None
    model: str = "gemini-2.0-flash"
```

**Process Flow**:
```python
@app.post("/agent-query")
  â”œâ”€> Validate dataset exists
  â”œâ”€> Validate API key
  â”œâ”€> Get dataset metadata (summary + column descriptions)
  â”œâ”€> Initialize GeminiDataFormulator
  â”œâ”€> Call generate_agent_actions()
  â”œâ”€> Track token usage
  â””â”€> Return: actions, reasoning, token_usage
```

**Response**:
```json
{
  "success": true,
  "actions": [...],
  "reasoning": "...",
  "token_usage": {
    "inputTokens": 1234,
    "outputTokens": 567,
    "totalTokens": 1801
  }
}
```

#### `GeminiDataFormulator.generate_agent_actions()`
**Location**: `/backend/gemini_llm.py`

**Purpose**: Core LLM interaction for action generation

**Process**:
```python
generate_agent_actions(query, canvas_state, dataset_id, dataset_metadata)
  â”œâ”€> Build enhanced context from metadata
  â”‚     â”œâ”€> Dataset purpose/summary
  â”‚     â””â”€> Column descriptions
  â”œâ”€> Summarize canvas state
  â”œâ”€> Construct comprehensive prompt
  â”‚     â”œâ”€> Dataset context
  â”‚     â”œâ”€> Canvas state
  â”‚     â”œâ”€> Available columns
  â”‚     â”œâ”€> Sample data
  â”‚     â”œâ”€> Action schemas
  â”‚     â””â”€> Selection guidelines
  â”œâ”€> Call run_gemini_with_usage()
  â”œâ”€> Parse JSON response
  â””â”€> Return: actions, reasoning, token_usage
```

**Enhanced Context**:
The prompt includes:
1. **Dataset Summary**: AI-generated description of data purpose
2. **Column Descriptions**: Semantic meaning of each column
3. **Canvas State**: What's already visualized
4. **Data Structure**: Available dimensions and measures
5. **Sample Data**: First 3 rows for reference
6. **Action Schemas**: Detailed format for each action type
7. **Guidelines**: When to use which action

#### Supporting Endpoints

1. **`/charts`** (existing)
   - Creates charts from dimensions + measures
   - Used by `create_chart` action

2. **`/chart-insights`** (existing)
   - Generates AI insights for a specific chart
   - Used by `generate_chart_insights` action

3. **`/ai-explore`** (modified)
   - Answers data questions
   - Now supports both `chart_id` AND `dataset_id`
   - Used by `ai_query` action

## Action Types Deep Dive

### 1. `create_chart`

**When to Use**: User wants to visualize data

**Required Fields**:
- `dimensions`: Array of column names (0-2)
- `measures`: Array of column names (1-2)
- `position`: Where to place chart

**Optional Fields**:
- `chartType`: Specific chart type (auto-detected if not provided)
- `referenceChartId`: For relative positioning

**Example**:
```json
{
  "type": "create_chart",
  "dimensions": ["state"],
  "measures": ["revenue"],
  "chartType": "bar",
  "position": "center",
  "reasoning": "Visualize revenue distribution across states"
}
```

### 2. `create_insight`

**When to Use**: User wants to add explanatory text

**Required Fields**:
- `text`: The insight/explanation text
- `position`: Where to place textbox

**Optional Fields**:
- `referenceChartId`: For relative positioning

**Example**:
```json
{
  "type": "create_insight",
  "text": "California leads with 35% of total revenue, driven by tech sector growth.",
  "position": "right_of_chart",
  "referenceChartId": "chart-123",
  "reasoning": "Explain the standout performer"
}
```

### 3. `generate_chart_insights`

**When to Use**: User wants AI explanation of a chart

**Required Fields**:
- `chartId`: Which chart to analyze
- `position`: Where to place insights

**Optional Fields**:
- `userContext`: Additional user-provided context

**Example**:
```json
{
  "type": "generate_chart_insights",
  "chartId": "chart-123",
  "position": "right_of_chart",
  "userContext": "Focus on Q3 spike",
  "reasoning": "User wants explanation of Q3 anomaly"
}
```

### 4. `ai_query` â­

**When to Use**: User asks a data question

**Required Fields**:
- `query`: The question to answer
- `position`: Where to place answer

**Optional Fields**:
- `chartId`: Specific chart context (auto-detected from selection)

**Smart Context Detection**:
1. If `chartId` provided â†’ use that chart's data
2. Else if chart selected â†’ use selected chart
3. Else â†’ query entire dataset

**Example**:
```json
{
  "type": "ai_query",
  "query": "What is the average capacity across sprints?",
  "position": "center",
  "reasoning": "Direct data question requiring calculation"
}
```

**Key Feature**: Works with or without charts! ðŸŽ‰

### 5. `show_table`

**When to Use**: User wants to see exact data values

**Required Fields**:
- `chartId`: Which chart's data to display

**Example**:
```json
{
  "type": "show_table",
  "chartId": "chart-123",
  "reasoning": "User wants to see precise numerical values"
}
```

**Note**: Pure client-side operation, no API call needed.

## Data Flow Examples

### Example 1: Simple Chart Creation

**User Query**: "Show revenue by state"

**Flow**:
```
1. User â†’ AgentChatPanel
   Input: "Show revenue by state"

2. AgentChatPanel â†’ canvasSnapshot
   Get current canvas state

3. AgentChatPanel â†’ Backend /agent-query
   POST { user_query, canvas_state, dataset_id }

4. Backend â†’ Gemini LLM
   Prompt with dataset + canvas context

5. Gemini â†’ Backend
   JSON: { actions: [{ type: "create_chart", dimensions: ["state"], measures: ["revenue"], ... }] }

6. Backend â†’ AgentChatPanel
   Validated response with token usage

7. AgentChatPanel â†’ validation.js
   Validate action schema

8. AgentChatPanel â†’ actionExecutor
   executeActions([create_chart_action])

9. actionExecutor â†’ Backend /charts
   POST { dimensions: ["state"], measures: ["revenue"] }

10. Backend â†’ actionExecutor
    Chart data with ECharts config

11. actionExecutor â†’ figureFromPayload
    Transform to ECharts format

12. actionExecutor â†’ setNodes
    Add chart node to canvas

13. Canvas â†’ User
    Chart appears on screen
```

### Example 2: AI Query (No Charts)

**User Query**: "What is the average capacity across sprints?"

**Flow**:
```
1. User â†’ AgentChatPanel
   Input: "What is the average capacity across sprints?"

2. AgentChatPanel â†’ canvasSnapshot
   Canvas state: { charts: [], tables: [], textBoxes: [] }

3. AgentChatPanel â†’ Backend /agent-query
   POST with empty canvas state

4. Backend â†’ Gemini LLM
   Detects query intent â†’ ai_query

5. Gemini â†’ Backend
   JSON: { actions: [{ type: "ai_query", query: "...", position: "center" }] }

6. Backend â†’ AgentChatPanel
   Validated response

7. AgentChatPanel â†’ actionExecutor
   executeActions([ai_query_action])

8. actionExecutor (smart detection):
   â”œâ”€> chartId from LLM? No
   â”œâ”€> Chart selected? No
   â””â”€> Use dataset_id âœ…

9. actionExecutor â†’ Backend /ai-explore
   POST { dataset_id, user_query }

10. Backend â†’ Gemini LLM
    Pandas code generation + execution

11. Backend â†’ actionExecutor
    Answer: "Average capacity is 42.5 story points"

12. actionExecutor â†’ setNodes
    Add textbox with Q&A

13. Canvas â†’ User
    Answer appears in text box
```

### Example 3: Complex Multi-Action

**User Query**: "Compare revenue by region and explain the top performer"

**Flow**:
```
1-6. [Same as Example 1]

7. Gemini â†’ Backend
   JSON: {
     actions: [
       { type: "create_chart", dimensions: ["region"], measures: ["revenue"], ... },
       { type: "generate_chart_insights", chartId: "NEWLY_CREATED", position: "right_of_chart", ... }
     ]
   }

8. actionExecutor
   Execute actions sequentially:
   
   Action 1: create_chart
   â”œâ”€> Call /charts
   â”œâ”€> Get chart data
   â”œâ”€> Create chart node (id: "chart-abc-123")
   â””â”€> Store chart_id

   Action 2: generate_chart_insights
   â”œâ”€> Use newly created chartId
   â”œâ”€> Call /chart-insights with chart-abc-123
   â”œâ”€> Get AI-generated insights
   â”œâ”€> Create textbox positioned right of chart
   â””â”€> Done

9. Canvas â†’ User
   Chart + Insights appear together
```

## Context Management

### Canvas Context (`canvasContext`)

Passed from `App.jsx` to `AgentChatPanel`:

```javascript
canvasContext = {
  editor: tldrawEditorRef.current,  // TLDraw editor instance
  nodes,                              // Current canvas nodes
  setNodes,                           // Update canvas nodes
  getViewportCenter,                  // Calculate center position
  API,                                // Backend API URL
  datasetId,                          // Current dataset ID
  apiKey,                             // Gemini API key
  figureFromPayload                   // Chart data transformer
}
```

### Dataset Metadata

Retrieved from `DATASET_METADATA` (generated during upload):

```python
{
  "success": True,
  "dataset_summary": "Sales data from 2023...",
  "columns": [
    {
      "name": "revenue",
      "type": "float64",
      "description": "Total revenue in USD, calculated as quantity Ã— unit_price"
    },
    ...
  ]
}
```

**Usage**: Provides semantic context to LLM for smarter action generation.

## Token Usage Tracking

### Flow:
```
1. Backend: GeminiDataFormulator.run_gemini_with_usage()
   â””â”€> Returns: (response, token_usage)

2. Backend: /agent-query endpoint
   â””â”€> Includes token_usage in response

3. Frontend: AgentChatPanel
   â””â”€> Calls onTokenUsage(usage) callback

4. Frontend: App.jsx
   â””â”€> Updates global tokenUsage state

5. Frontend: AI Settings Panel
   â””â”€> Displays cumulative usage and cost
```

### Cost Calculation:
```javascript
// Gemini 2.0 Flash pricing
const inputCost = (inputTokens / 1000000) * 0.075;
const outputCost = (outputTokens / 1000000) * 0.30;
const estimatedCost = inputCost + outputCost;
```

## Error Handling

### Frontend Errors:

1. **No Dataset**: "Please upload a dataset first"
2. **No API Key**: "Please configure your Gemini API key"
3. **Validation Failed**: Zod error details displayed
4. **Execution Failed**: Specific action error shown
5. **Network Error**: HTTP error from backend

### Backend Errors:

1. **404**: Dataset/Chart not found
2. **400**: Invalid request (missing fields)
3. **500**: LLM failure, parsing error, execution error

### Graceful Degradation:

- If some actions fail, others still execute
- Partial success is reported clearly
- User can retry or rephrase query

## Performance Considerations

### Token Usage (Typical):
- Empty canvas: ~800 tokens
- With 3 charts: ~1200 tokens
- With metadata: +300-500 tokens
- Response: ~200-500 tokens

### Response Time:
- Canvas snapshot: <50ms
- Backend /agent-query: 1-3 seconds
- Action execution: 1-5 seconds (depending on actions)
- Total: 2-8 seconds

### Optimization:
- Canvas snapshot is lightweight (only essential data)
- Dataset metadata cached after upload
- Client-side actions (show_table) are instant
- Actions execute sequentially for dependency handling

## Security

### API Key:
- Stored in browser localStorage
- Never logged or exposed
- Sent with every Gemini request
- User-controlled

### Data:
- Dataset stored in backend memory
- Not persisted to disk
- Cleared on server restart
- HTTPS encryption for all API calls

## Limitations

### Current Constraints:
- Max 5 actions per query
- Charts can be created but not modified
- No arrow/connector creation
- No layout auto-arrangement
- No conversation memory across sessions

### Technical Limits:
- Requires Gemini API quota
- Requires dataset upload first
- TLDraw editor must be initialized
- Browser must support modern JavaScript

## Future Enhancements

### Planned Features:
1. **Chart Modification**: Edit existing charts (filters, type, colors)
2. **Arrow Creation**: Show relationships between elements
3. **Layout Management**: Auto-arrange canvas smartly
4. **Conversation Memory**: Multi-turn contextual conversations
5. **Batch Operations**: "Create 5 different views of this data"
6. **Export**: Save analysis as PDF/Markdown
7. **Undo/Redo**: Fine-grained action history
8. **Templates**: "Create a sales dashboard"

### Architecture Improvements:
1. **Action Queue**: Parallel execution where possible
2. **Caching**: Store common query results
3. **Streaming**: Show actions as they execute
4. **Webhooks**: Notify on long-running operations

## Testing Strategy

### Unit Tests:
- Validation schemas (Zod)
- Action executors (mock API calls)
- Canvas snapshot extraction
- Position calculations

### Integration Tests:
- Full flow: query â†’ actions â†’ canvas
- Error handling paths
- Token usage tracking
- Multi-action sequences

### E2E Tests:
```javascript
// Test 1: Simple chart creation
await agent.query("Show revenue by state");
expect(canvas.charts).toHaveLength(1);

// Test 2: AI query without charts
await agent.query("What is the average revenue?");
expect(canvas.textBoxes).toContain("Average revenue");

// Test 3: Multi-action
await agent.query("Compare sales and explain trends");
expect(canvas.charts).toHaveLength(1);
expect(canvas.textBoxes).toHaveLength(1);
```

## Debugging

### Frontend Console:
```javascript
// Canvas state
console.log(getCanvasSnapshot(editor, nodes));

// Action execution
console.log("ðŸ¤– Executing action:", action);

// Results
console.log("âœ… Action completed:", result);
```

### Backend Logging:
```python
print(f"ðŸ¤– Agent query received: '{request.user_query}'")
print(f"ðŸ“‹ Using dataset metadata: {has_metadata}")
print(f"âœ… Generated {len(actions)} actions")
print(f"ðŸ“Š Token usage: {token_usage}")
```

### Browser DevTools:
- Network tab: Check API requests/responses
- Console: Check error messages and logs
- React DevTools: Inspect component state

## File Structure Summary

```
frontend/src/agentic_layer/
â”œâ”€â”€ index.js                    # Public API exports
â”œâ”€â”€ types.js                    # Constants and config
â”œâ”€â”€ validation.js               # Zod schemas (5 action types)
â”œâ”€â”€ canvasSnapshot.js           # Canvas state extraction
â”œâ”€â”€ actionExecutor.js           # Action handlers (5 handlers)
â””â”€â”€ AgentChatPanel.jsx          # UI component

backend/
â”œâ”€â”€ app.py                      # /agent-query endpoint
â””â”€â”€ gemini_llm.py               # LLM interaction + prompts

docs/
â”œâ”€â”€ AGENTIC_LAYER_COMPLETE_ARCHITECTURE.md    # This file
â”œâ”€â”€ AGENTIC_LAYER_EXPANSIONS.md               # Feature details
â”œâ”€â”€ AGENTIC_LAYER_USER_GUIDE.md               # User documentation
â””â”€â”€ AI_QUERY_INDEPENDENT_FIX.md               # Recent fix details
```

---

## Quick Reference

### Action Type Selection Guide

| User Intent | Action Type | Charts Required? |
|------------|-------------|------------------|
| "Show X by Y" | `create_chart` | No |
| "Add note about..." | `create_insight` | No |
| "Explain this chart" | `generate_chart_insights` | Yes |
| "What is the average...?" | `ai_query` | No |
| "Show data table" | `show_table` | Yes |

### Position Types

| Position | Behavior |
|----------|----------|
| `center` | Viewport center |
| `right_of_chart` | 850px right of reference chart |
| `below_chart` | 450px below reference chart |
| `auto` | Same as `center` |

### Context Detection Priority (ai_query)

1. Explicit `chartId` in action
2. Selected chart in editor
3. Dataset-level (fallback)

---

**Last Updated**: November 2025  
**Version**: 1.0  
**Status**: Production Ready âœ…

